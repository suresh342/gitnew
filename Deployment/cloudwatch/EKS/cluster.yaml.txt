---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: my-eks-cluster
  region: ap-south-1
  version: "1.21"

iam:
  withOIDC: true

addons:
- name: vpc-cni # no version is specified so it deploys the default version
  attachPolicyARNs:
    - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
- name: coredns
  version: latest # auto discovers the latest available
- name: kube-proxy
  version: latest

# vpc:
#   id: "vpc-0b72069871d6bbe84"  # (optional, must match VPC ID used for each subnet below)
#   cidr: "10.1.0.0/16"       # (optional, must match CIDR used by the given VPC)
#   subnets:
#     public:
#       ap-south-1a:
#         id: "subnet-09719b87e3b9ee9fc"
#         cidr: "10.1.0.0/20"
#       ap-south-1b:
#         id: "subnet-0827a39e2c2543fb3"
#         cidr: "10.1.16.0/20"
#     # must provide 'private' and/or 'public' subnets by availibility zone as shown
#     private:
#       ap-south-1a:
#         id: "subnet-03a6bcab0aee1bed3"
#         cidr: "10.1.128.0/20" # (optional, must match CIDR used by the given subnet)
#
#       ap-south-1b:
#         id: "subnet-022671ba6eaeec6cf"
#         cidr: "10.1.144.0/20"  # (optional, must match CIDR used by the given subnet)


managedNodeGroups:
  - name: managed-eks-ng-1
    instanceType: t2.medium
    minSize: 2
    desiredCapacity: 2
    maxSize: 4
    volumeSize: 50
    updateConfig:
      maxUnavailable: 1
    labels: {role: worker}
    ssh:
      publicKeyName: eks cluster
    tags:
      nodegroup-role: worker
    iam:
      withAddonPolicies:
        externalDNS: true
        certManager: true
    privateNetworking: true # if only 'Private' subnets are given, this must be enabled
